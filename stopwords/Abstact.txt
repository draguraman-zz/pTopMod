Phrase Extraction and Topic Modeling using Latent Dirichlet Allocation

ABSTRACT :
The traditional topic models involves the bag of words assumption and have a very fixed topic assignment where in the words of the corpus belong wholly to a predetermined set of topics or do not belong at all.The more recent methods tried to solve the above problem by employing a probabilistic latent semantic allocation where in the topics were a distribution of words with different words occurding in different set of topics with different probabilities. This kind of approach provided a much better set of topics,  the Latent Dirichlet Allocation, that we used for our project, is essentially an extension of the Probabilistic Semantic Allocation, the major difference from PLSI being that it posits the documents of the corpus to be essentially containing a distribution of topics where the distribution is assumed to have a dirichlet prior. Our work involved topic modeling for a corpus from fourteen different languages.We use the  europarl data set available in these fourteen languages which summarize the proceedings of  european parliamentary session.We processed the corpus after removing the stop words and stemming into the array of lines and a modified frequent pattern growth algorithm was employed to frequent out the patterns for each language. Some Frequent patterns can be inherent to the language itself and may not really reflect on the nature of topic distribution in the corpus, thus we performed a confidence testing to weed out such frequent patterns  that are non discriminatory and are inherently biased in the document and on this final processed  listof frequent patterns, we applied the a variant LDA for topic modeling to generate the topic distribution.